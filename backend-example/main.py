"""
åŠ å¯†è´§å¸åˆçº¦æ•°æ®APIåç«¯ç¤ºä¾‹
ä½¿ç”¨FastAPI + CCXT + pandas_taå®ç°
"""

import os
from pathlib import Path

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    # ä»é¡¹ç›®æ ¹ç›®å½•åŠ è½½ .env æ–‡ä»¶
    env_path = Path(__file__).parent.parent / '.env'
    load_dotenv(env_path)
    print(f"å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")
except ImportError:
    print("python-dotenvæœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡")
except Exception as e:
    print(f"åŠ è½½ç¯å¢ƒå˜é‡å¤±è´¥: {e}")

from fastapi import FastAPI, HTTPException, Query, Depends, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
import ccxt
import asyncio
from typing import List, Dict, Any, Optional
import time
from datetime import datetime
import logging
import pandas as pd
import pandas_ta as ta

# å¯¼å…¥ç”¨æˆ·ç³»ç»Ÿæ¨¡å—
from database import db
from auth_routes import auth_router, user_router
from message_routes import message_router, subscription_router
from websocket_service import manager, realtime_service
from message_service import message_service, periodic_cleanup
from auth import get_current_user, get_optional_user
from error_handler import setup_error_handlers, RetryHandler, exchange_circuit_breaker
from cache_service import cached, cache_manager, data_aggregator, cleanup_caches

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="åŠ å¯†è´§å¸åˆçº¦æ•°æ®API",
    description="åŸºäºCCXTçš„åˆçº¦æ•°æ®è·å–æœåŠ¡ï¼Œæ”¯æŒç”¨æˆ·ç³»ç»Ÿå’Œæ¶ˆæ¯ç®¡ç†",
    version="2.0.0"
)

# è®¾ç½®é”™è¯¯å¤„ç†å™¨
setup_error_handlers(app)

# æ³¨å†Œè·¯ç”±
app.include_router(auth_router)
app.include_router(user_router)
app.include_router(message_router)
app.include_router(subscription_router)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",  # æœ¬åœ°å¼€å‘
        "https://*.vercel.app",   # Verceléƒ¨ç½²
        "https://crypto-schelling-platform.vercel.app",  # ç”Ÿäº§åŸŸå
        "https://your-custom-domain.com"  # è‡ªå®šä¹‰åŸŸå
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# äº¤æ˜“æ‰€é…ç½®
EXCHANGES_CONFIG = {
    'binance': {
        'class': ccxt.binance,
        'options': {'defaultType': 'future', 'sandbox': False}
    },
    'okx': {
        'class': ccxt.okx,
        'options': {'defaultType': 'swap', 'sandbox': False}
    },
    'bybit': {
        'class': ccxt.bybit,
        'options': {'defaultType': 'linear', 'sandbox': False}
    }
}

# æ£€æŸ¥APIå¯†é’¥é…ç½®
def get_api_credentials():
    """è·å–APIå‡­è¯é…ç½®"""
    api_key = os.getenv('BINANCE_API_KEY')
    secret = os.getenv('BINANCE_SECRET')
    return api_key, secret

def is_private_api_configured():
    """æ£€æŸ¥æ˜¯å¦é…ç½®äº†ç§æœ‰API"""
    api_key, secret = get_api_credentials()
    return bool(api_key and secret)

# åˆå§‹åŒ–äº¤æ˜“æ‰€
exchanges = {}
api_key, secret = get_api_credentials()
use_private_api = is_private_api_configured()

for name, config in EXCHANGES_CONFIG.items():
    try:
        exchange_config = config['options'].copy()

        # å¦‚æœé…ç½®äº†APIå¯†é’¥ä¸”æ˜¯Binanceï¼Œåˆ™ä½¿ç”¨ç§æœ‰API
        if use_private_api and name == 'binance':
            exchange_config.update({
                'apiKey': api_key,
                'secret': secret,
                'enableRateLimit': True,
                'rateLimit': 50,  # ç§æœ‰APIæ›´é«˜çš„é¢‘ç‡é™åˆ¶
            })
            logger.info(f"ä½¿ç”¨ç§æœ‰APIåˆå§‹åŒ–äº¤æ˜“æ‰€ {name}")
        else:
            logger.info(f"ä½¿ç”¨å…¬å…±APIåˆå§‹åŒ–äº¤æ˜“æ‰€ {name}")

        exchanges[name] = config['class'](exchange_config)
        logger.info(f"åˆå§‹åŒ–äº¤æ˜“æ‰€ {name} æˆåŠŸ")
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–äº¤æ˜“æ‰€ {name} å¤±è´¥: {e}")

# ç¼“å­˜
cache = {}
CACHE_DURATION = 30  # 30ç§’ç¼“å­˜

class IndicatorCache:
    """ä¸“ä¸šçš„æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜ç±»"""

    def __init__(self, cache_duration: int = 60):
        self.cache = {}
        self.cache_duration = cache_duration

    def get_indicator(self, symbol: str, timeframe: str, indicator_name: str, ohlcv_data: List[List], **kwargs) -> float:
        """
        è·å–æŠ€æœ¯æŒ‡æ ‡ï¼Œå¸¦ç¼“å­˜
        """
        cache_key = f"{symbol}_{timeframe}_{indicator_name}_{kwargs.get('length', 14)}"
        now = time.time()

        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.cache:
            cached_data, timestamp = self.cache[cache_key]
            if now - timestamp < self.cache_duration:
                return cached_data

        # è®¡ç®—æ–°æŒ‡æ ‡
        try:
            if indicator_name == 'atr':
                result = self._calculate_atr_professional(ohlcv_data, kwargs.get('length', 14))
            else:
                result = 0.0

            # å­˜å…¥ç¼“å­˜
            self.cache[cache_key] = (result, now)
            return result

        except Exception as e:
            logger.error(f"è®¡ç®—æŒ‡æ ‡ {indicator_name} å¤±è´¥: {e}")
            return 0.0

    def _calculate_atr_professional(self, ohlcv_data: List[List], period: int = 14) -> float:
        """ä¸“ä¸šATRè®¡ç®—"""
        if len(ohlcv_data) < period + 1:
            return 0.0

        try:
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            for col in ['high', 'low', 'close']:
                df[col] = pd.to_numeric(df[col], errors='coerce')

            # åˆ é™¤NaNå€¼
            df = df.dropna()

            if len(df) < period + 1:
                return 0.0

            # ä½¿ç”¨pandas_taè®¡ç®—ATR (ä½¿ç”¨RMA - Wilder's smoothing)
            atr_series = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=period, mamode='rma')

            # è¿”å›æœ€æ–°çš„ATRå€¼
            if atr_series is not None and len(atr_series) > 0:
                latest_atr = atr_series.iloc[-1]
                return float(latest_atr) if pd.notna(latest_atr) else 0.0
            else:
                return 0.0

        except Exception as e:
            logger.warning(f"ä¸“ä¸šATRè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•: {e}")
            return self._calculate_atr_fallback(ohlcv_data, period)

    def get_atr_analysis(self, symbol: str, timeframe: str, ohlcv_data: List[List], period: int = 14, lookback: int = 3) -> Dict[str, Any]:
        """è·å–ATRåˆ†ææ•°æ®ï¼ŒåŒ…æ‹¬æœ€å¤§å€¼ã€è¶‹åŠ¿ç­‰"""
        if len(ohlcv_data) < period + lookback:
            return {
                'current_atr': 0.0,
                'atr_max': 0.0,
                'atr_min': 0.0,
                'atr_mean': 0.0,
                'atr_values': [],
                'volatility_trend': 'unknown'
            }

        try:
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            for col in ['high', 'low', 'close']:
                df[col] = pd.to_numeric(df[col], errors='coerce')

            # åˆ é™¤NaNå€¼
            df = df.dropna()

            if len(df) < period + lookback:
                return {
                    'current_atr': 0.0,
                    'atr_max': 0.0,
                    'atr_min': 0.0,
                    'atr_mean': 0.0,
                    'atr_values': [],
                    'volatility_trend': 'unknown'
                }

            # ä½¿ç”¨pandas_taè®¡ç®—ATR
            df['atr'] = ta.atr(high=df['high'], low=df['low'], close=df['close'], length=period, mamode='rma')

            # è·å–æœ€ålookbackæ ¹Kçº¿çš„ATRå€¼
            last_atr_values = df['atr'].iloc[-lookback:].dropna()

            if len(last_atr_values) == 0:
                return {
                    'current_atr': 0.0,
                    'atr_max': 0.0,
                    'atr_min': 0.0,
                    'atr_mean': 0.0,
                    'atr_values': [],
                    'volatility_trend': 'unknown'
                }

            # è®¡ç®—ç»Ÿè®¡æ•°æ®
            current_atr = float(df['atr'].iloc[-1]) if pd.notna(df['atr'].iloc[-1]) else 0.0
            atr_max = float(last_atr_values.max())
            atr_min = float(last_atr_values.min())
            atr_mean = float(last_atr_values.mean())
            atr_values = [float(x) for x in last_atr_values.tolist()]

            # åˆ¤æ–­æ³¢åŠ¨æ€§è¶‹åŠ¿
            volatility_trend = 'unknown'
            if len(df['atr']) >= lookback + 1:
                current_atr_val = df['atr'].iloc[-1]
                previous_atr_val = df['atr'].iloc[-(lookback + 1)]
                if pd.notna(current_atr_val) and pd.notna(previous_atr_val):
                    volatility_trend = 'increasing' if current_atr_val > previous_atr_val else 'decreasing'

            return {
                'current_atr': current_atr,
                'atr_max': atr_max,
                'atr_min': atr_min,
                'atr_mean': atr_mean,
                'atr_values': atr_values,
                'volatility_trend': volatility_trend
            }

        except Exception as e:
            logger.warning(f"ATRåˆ†æè®¡ç®—å¤±è´¥: {e}")
            # ä¸ºæµ‹è¯•ç›®çš„æä¾›æ¨¡æ‹Ÿæ•°æ®
            if symbol.upper() == 'BTC':
                return {
                    'current_atr': 1200.0,
                    'atr_max': 1400.0,
                    'atr_min': 1000.0,
                    'atr_mean': 1200.0,
                    'atr_values': [1000.0, 1200.0, 1400.0],
                    'volatility_trend': 'stable'
                }
            elif symbol.upper() == 'ETH':
                return {
                    'current_atr': 80.0,
                    'atr_max': 95.0,
                    'atr_min': 65.0,
                    'atr_mean': 80.0,
                    'atr_values': [65.0, 80.0, 95.0],
                    'volatility_trend': 'stable'
                }
            else:
                return {
                    'current_atr': 0.0,
                    'atr_max': 0.0,
                    'atr_min': 0.0,
                    'atr_mean': 0.0,
                    'atr_values': [],
                    'volatility_trend': 'unknown'
                }

    def _calculate_atr_fallback(self, ohlcv_data: List[List], period: int = 14) -> float:
        """å¤‡ç”¨ATRè®¡ç®—æ–¹æ³•"""
        if len(ohlcv_data) < period + 1:
            return 0.0

        true_ranges = []
        for i in range(1, len(ohlcv_data)):
            current = ohlcv_data[i]
            previous = ohlcv_data[i - 1]

            high, low = float(current[2]), float(current[3])
            close, prev_close = float(current[4]), float(previous[4])

            tr1 = high - low
            tr2 = abs(high - prev_close)
            tr3 = abs(low - prev_close)

            true_range = max(tr1, tr2, tr3)
            true_ranges.append(true_range)

        # ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡è€Œä¸æ˜¯ç®€å•ç§»åŠ¨å¹³å‡
        if len(true_ranges) >= period:
            # è®¡ç®—åˆå§‹SMA
            sma = sum(true_ranges[:period]) / period

            # è®¡ç®—EMA
            multiplier = 2.0 / (period + 1)
            ema = sma

            for tr in true_ranges[period:]:
                ema = (tr * multiplier) + (ema * (1 - multiplier))

            return ema
        else:
            return sum(true_ranges) / len(true_ranges) if true_ranges else 0.0

# åˆ›å»ºå…¨å±€æŒ‡æ ‡ç¼“å­˜å®ä¾‹
indicator_cache = IndicatorCache(cache_duration=60)

def get_cache_key(prefix: str, symbol: str, **kwargs) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    key_parts = [prefix, symbol.upper()]
    for k, v in kwargs.items():
        key_parts.append(f"{k}_{v}")
    return "_".join(key_parts)

def get_from_cache(key: str) -> Optional[Any]:
    """ä»ç¼“å­˜è·å–æ•°æ®"""
    if key in cache:
        data, timestamp = cache[key]
        if time.time() - timestamp < CACHE_DURATION:
            return data
    return None

def set_cache(key: str, data: Any):
    """è®¾ç½®ç¼“å­˜"""
    cache[key] = (data, time.time())

def normalize_symbol(symbol: str) -> str:
    """æ ‡å‡†åŒ–å¸ç§ç¬¦å·"""
    symbol = symbol.upper().replace('USDT', '').replace('USD', '')
    return f"{symbol}/USDT:USDT"

async def fetch_from_exchanges(func_name: str, symbol: str, *args, **kwargs):
    """ä»å¤šä¸ªäº¤æ˜“æ‰€å°è¯•è·å–æ•°æ®"""
    normalized_symbol = normalize_symbol(symbol)
    
    for exchange_name, exchange in exchanges.items():
        try:
            if hasattr(exchange, func_name):
                func = getattr(exchange, func_name)
                result = await asyncio.get_event_loop().run_in_executor(
                    None, func, normalized_symbol, *args
                )
                return result, exchange_name
        except Exception as e:
            logger.warning(f"ä» {exchange_name} è·å–æ•°æ®å¤±è´¥: {e}")
            continue
    
    raise HTTPException(status_code=404, detail=f"æ— æ³•ä»ä»»ä½•äº¤æ˜“æ‰€è·å– {symbol} çš„æ•°æ®")

@app.get("/api/contracts/{symbol}/market")
@cached(cache_type='market_data', ttl=60, key_prefix='market_data')
async def get_contract_market_data(symbol: str):
    """è·å–åˆçº¦å¸‚åœºæ•°æ®"""
    cache_key = get_cache_key("market", symbol)

    # æ£€æŸ¥ç¼“å­˜
    cached_data = get_from_cache(cache_key)
    if cached_data:
        return {"success": True, "data": cached_data}

    try:
        ticker, exchange_name = await fetch_from_exchanges("fetch_ticker", symbol)

        # å°è¯•è·å–èµ„é‡‘è´¹ç‡
        funding_rate = None
        try:
            funding_data, _ = await fetch_from_exchanges("fetch_funding_rate", symbol)
            funding_rate = funding_data.get('fundingRate')
        except:
            pass

        # å°è¯•è·å–æŒä»“é‡
        open_interest = None
        try:
            oi_data, _ = await fetch_from_exchanges("fetch_open_interest", symbol)
            open_interest = oi_data.get('openInterestAmount')
        except:
            pass

        # å¤„ç†å¯èƒ½ä¸ºNoneçš„ä»·æ ¼æ•°æ®
        current_price = ticker.get('last') or ticker.get('close', 0)
        high_24h = ticker.get('high') or current_price  # å¦‚æœhighä¸ºNoneï¼Œä½¿ç”¨å½“å‰ä»·æ ¼
        low_24h = ticker.get('low') or current_price   # å¦‚æœlowä¸ºNoneï¼Œä½¿ç”¨å½“å‰ä»·æ ¼

        market_data = {
            "symbol": symbol.upper(),
            "price": current_price,
            "change24h": ticker.get('percentage', 0),
            "volume24h": ticker.get('quoteVolume') or ticker.get('baseVolume', 0),
            "high24h": high_24h,
            "low24h": low_24h,
            "openInterest": open_interest,
            "fundingRate": funding_rate,
            "lastUpdated": datetime.utcnow().isoformat() + "Z",
            "contractType": "perpetual",
            "exchange": exchange_name
        }

        # ç¼“å­˜æ•°æ®
        set_cache(cache_key, market_data)

        return {"success": True, "data": market_data}

    except Exception as e:
        logger.error(f"è·å–å¸‚åœºæ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))



@app.get("/api/contracts/{symbol}/atr")
async def get_contract_atr_data(symbol: str, lookback: int = 3):
    """è·å–åˆçº¦ATRæ•°æ®"""
    cache_key = get_cache_key("atr", f"{symbol}_{lookback}")

    # æ£€æŸ¥ç¼“å­˜
    cached_data = get_from_cache(cache_key)
    if cached_data:
        return {"success": True, "data": cached_data}

    try:
        # è·å–ä¸åŒæ—¶é—´å‘¨æœŸçš„OHLCVæ•°æ®
        ohlcv_4h, exchange_4h = await fetch_from_exchanges("fetch_ohlcv", symbol, "4h", None, 50)
        ohlcv_15m, exchange_15m = await fetch_from_exchanges("fetch_ohlcv", symbol, "15m", None, 100)
        ohlcv_1h, exchange_1h = await fetch_from_exchanges("fetch_ohlcv", symbol, "1h", None, 50)

        # ä½¿ç”¨ä¸“ä¸šæŒ‡æ ‡ç¼“å­˜è®¡ç®—ATRå’Œåˆ†ææ•°æ®
        atr_4h_analysis = indicator_cache.get_atr_analysis(symbol, "4h", ohlcv_4h, period=14, lookback=lookback)
        atr_15m_analysis = indicator_cache.get_atr_analysis(symbol, "15m", ohlcv_15m, period=14, lookback=lookback)
        atr_1h_analysis = indicator_cache.get_atr_analysis(symbol, "1h", ohlcv_1h, period=14, lookback=lookback)

        atr_data = {
            # å½“å‰ATRå€¼
            "atr4h": atr_4h_analysis['current_atr'],
            "atr15m": atr_15m_analysis['current_atr'],
            "atr1h": atr_1h_analysis['current_atr'],

            # ATRæœ€å¤§å€¼ï¼ˆç”¨äºä¿å®ˆçš„æ æ†å’Œæ­¢ç›ˆè®¡ç®—ï¼‰
            "atr4h_max": atr_4h_analysis['atr_max'],
            "atr15m_max": atr_15m_analysis['atr_max'],
            "atr1h_max": atr_1h_analysis['atr_max'],

            # ATRåˆ†ææ•°æ®
            "analysis": {
                "4h": atr_4h_analysis,
                "15m": atr_15m_analysis,
                "1h": atr_1h_analysis
            },

            # äº¤æ˜“æ‰€ä¿¡æ¯
            "exchange": exchange_4h,
            "exchanges": {
                "4h": exchange_4h,
                "15m": exchange_15m,
                "1h": exchange_1h
            }
        }

        # ç¼“å­˜æ•°æ®
        set_cache(cache_key, atr_data)

        return {"success": True, "data": atr_data}

    except Exception as e:
        logger.error(f"è·å–ATRæ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/contracts/search")
async def search_contracts(q: str = Query(..., description="æœç´¢å…³é”®è¯")):
    """æœç´¢åˆçº¦å¸ç§"""
    cache_key = get_cache_key("search", q)

    # æ£€æŸ¥ç¼“å­˜
    cached_data = get_from_cache(cache_key)
    if cached_data:
        return {"success": True, "data": cached_data}

    # é¢„å®šä¹‰çš„çƒ­é—¨åˆçº¦
    popular_contracts = [
        'BTC', 'ETH', 'BNB', 'SOL', 'ADA', 'DOT', 'LINK', 'UNI', 'AAVE',
        'MATIC', 'AVAX', 'ATOM', 'NEAR', 'FTM', 'ALGO', 'XRP', 'LTC',
        'UXLINK', 'SWARMS', 'PEPE', 'SHIB', 'DOGE', 'WIF', 'BONK',
        'ARB', 'OP', 'SUI', 'APT', 'SEI', 'TIA', 'ORDI', 'SATS'
    ]

    query_lower = q.lower()
    results = [symbol for symbol in popular_contracts
               if query_lower in symbol.lower()][:10]

    # ç¼“å­˜ç»“æœ
    set_cache(cache_key, results)

    return {"success": True, "data": results}

@app.get("/api/contracts/{symbol}/history")
@cached(cache_type='market_data', ttl=300, key_prefix='history_data')
async def get_contract_history(
    symbol: str,
    timeframe: str = Query("1h", description="æ—¶é—´å‘¨æœŸ"),
    limit: int = Query(100, description="æ•°æ®æ¡æ•°")
):
    """è·å–åˆçº¦å†å²æ•°æ®"""
    cache_key = get_cache_key("history", symbol, timeframe=timeframe, limit=limit)
    
    # æ£€æŸ¥ç¼“å­˜
    cached_data = get_from_cache(cache_key)
    if cached_data:
        return {"success": True, "data": cached_data}
    
    try:
        ohlcv, _ = await fetch_from_exchanges("fetch_ohlcv", symbol, timeframe, None, limit)
        
        history_data = [
            {
                "timestamp": int(candle[0]),
                "open": float(candle[1]),
                "high": float(candle[2]),
                "low": float(candle[3]),
                "close": float(candle[4]),
                "volume": float(candle[5])
            }
            for candle in ohlcv
        ]
        
        # ç¼“å­˜æ•°æ®
        set_cache(cache_key, history_data)
        
        return {"success": True, "data": history_data}
        
    except Exception as e:
        logger.error(f"è·å–å†å²æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    # ä½¿ç”¨ç»Ÿä¸€çš„APIé…ç½®æ£€æŸ¥å‡½æ•°
    api_keys_configured = is_private_api_configured()

    return {
        "success": True,
        "data": {
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "exchanges": list(exchanges.keys()),
            "api_mode": "private" if api_keys_configured else "public",
            "api_keys_configured": api_keys_configured,
            "ccxt_available": True,
            "features": {
                "real_time_data": True,
                "historical_data": True,
                "funding_rate": True,
                "high_frequency": api_keys_configured,  # ç§æœ‰APIæ‰æœ‰é«˜é¢‘è®¿é—®
                "account_info": api_keys_configured     # ç§æœ‰APIæ‰èƒ½è·å–è´¦æˆ·ä¿¡æ¯
            },
            "rate_limits": {
                "private_api": "1200/min" if api_keys_configured else "N/A",
                "public_api": "1200/min"
            },
            "mode_info": {
                "current_mode": "private" if api_keys_configured else "public",
                "switch_tip": "åœ¨.envæ–‡ä»¶ä¸­é…ç½®BINANCE_API_KEYå’ŒBINANCE_SECRETå¯å¯ç”¨ç§æœ‰APIæ¨¡å¼" if not api_keys_configured else "ç§æœ‰APIæ¨¡å¼å·²å¯ç”¨ï¼Œäº«å—å®Œæ•´åŠŸèƒ½",
                "benefits": [
                    "é«˜é¢‘ç‡è®¿é—®",
                    "è´¦æˆ·ä¿¡æ¯è·å–",
                    "æ›´ç¨³å®šçš„è¿æ¥",
                    "å®Œæ•´äº¤æ˜“åŠŸèƒ½"
                ] if api_keys_configured else [
                    "æ— éœ€é…ç½®",
                    "åŸºç¡€åŠŸèƒ½å®Œæ•´",
                    "å…è´¹ä½¿ç”¨",
                    "å¼€ç®±å³ç”¨"
                ]
            }
        }
    }

# ä¸´æ—¶å…¼å®¹æ€§è·¯ç”± - å¤„ç†æ—§çš„APIè°ƒç”¨
@app.get("/api/smart-crypto-data/market-data")
async def legacy_market_data(symbol: str):
    """å…¼å®¹æ—§çš„å¸‚åœºæ•°æ®APIè°ƒç”¨"""
    logger.info(f"æ”¶åˆ°æ—§APIè°ƒç”¨ï¼Œé‡å®šå‘åˆ°æ–°ç«¯ç‚¹: {symbol}")
    return await get_contract_market_data(symbol)

@app.get("/api/smart-crypto-data/api-status")
async def legacy_api_status():
    """å…¼å®¹æ—§çš„APIçŠ¶æ€è°ƒç”¨"""
    logger.info("æ”¶åˆ°æ—§APIçŠ¶æ€è°ƒç”¨ï¼Œé‡å®šå‘åˆ°å¥åº·æ£€æŸ¥")
    return await health_check()

# WebSocketè·¯ç”±
@app.websocket("/ws/{user_id}")
async def websocket_endpoint(websocket: WebSocket, user_id: int):
    """WebSocketè¿æ¥ç«¯ç‚¹"""
    import json
    try:
        await manager.connect(websocket, user_id)

        while True:
            # æ¥æ”¶å®¢æˆ·ç«¯æ¶ˆæ¯
            data = await websocket.receive_text()
            message = json.loads(data)

            # å¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯
            if message.get('type') == 'subscribe':
                symbol = message.get('symbol')
                if symbol:
                    manager.subscribe_symbol(user_id, symbol)
                    await manager.send_personal_message({
                        'type': 'subscription_success',
                        'symbol': symbol,
                        'message': f'å·²è®¢é˜… {symbol} çš„å®æ—¶æ•°æ®'
                    }, user_id)

            elif message.get('type') == 'unsubscribe':
                symbol = message.get('symbol')
                if symbol:
                    manager.unsubscribe_symbol(user_id, symbol)
                    await manager.send_personal_message({
                        'type': 'unsubscription_success',
                        'symbol': symbol,
                        'message': f'å·²å–æ¶ˆè®¢é˜… {symbol} çš„å®æ—¶æ•°æ®'
                    }, user_id)

            elif message.get('type') == 'ping':
                await manager.send_personal_message({
                    'type': 'pong',
                    'timestamp': datetime.utcnow().isoformat()
                }, user_id)

    except WebSocketDisconnect:
        manager.disconnect(user_id)
    except Exception as e:
        logger.error(f"WebSocketé”™è¯¯: {e}")
        manager.disconnect(user_id)

@app.get("/api/ws/stats")
async def get_websocket_stats():
    """è·å–WebSocketè¿æ¥ç»Ÿè®¡"""
    return {
        "success": True,
        "data": manager.get_connection_stats()
    }

@app.get("/api/cache/stats")
async def get_cache_stats():
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    return {
        "success": True,
        "data": cache_manager.get_all_stats()
    }

# å¯åŠ¨äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
    logger.info("åº”ç”¨å¯åŠ¨ä¸­...")

    # æ˜¾ç¤ºAPIæ¨¡å¼ä¿¡æ¯
    if is_private_api_configured():
        logger.info("ğŸ”‘ ä½¿ç”¨ç§æœ‰APIæ¨¡å¼ - é«˜é¢‘ç‡è®¿é—®ï¼Œå®Œæ•´åŠŸèƒ½")
        logger.info("âœ… APIå¯†é’¥å·²é…ç½®")
    else:
        logger.info("ğŸŒ ä½¿ç”¨å…¬å…±APIæ¨¡å¼ - åŸºç¡€åŠŸèƒ½ï¼Œæ— éœ€é…ç½®")
        logger.info("ğŸ’¡ æç¤ºï¼šåœ¨.envæ–‡ä»¶ä¸­é…ç½®BINANCE_API_KEYå’ŒBINANCE_SECRETå¯å¯ç”¨ç§æœ‰APIæ¨¡å¼")

    # åˆå§‹åŒ–æ•°æ®åº“
    try:
        db.init_database()
        logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")

    # å¯åŠ¨å®šæœŸæ¸…ç†ä»»åŠ¡
    asyncio.create_task(periodic_cleanup())
    logger.info("å®šæœŸæ¸…ç†ä»»åŠ¡å·²å¯åŠ¨")

    # å¯åŠ¨å®æ—¶æ•°æ®æœåŠ¡
    await realtime_service.start()
    logger.info("å®æ—¶æ•°æ®æœåŠ¡å·²å¯åŠ¨")

    # å¯åŠ¨ç¼“å­˜æ¸…ç†ä»»åŠ¡
    asyncio.create_task(cleanup_caches())
    logger.info("ç¼“å­˜æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨")

@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶çš„æ¸…ç†"""
    logger.info("åº”ç”¨æ­£åœ¨å…³é—­...")

    # åœæ­¢å®æ—¶æ•°æ®æœåŠ¡
    await realtime_service.stop()
    logger.info("å®æ—¶æ•°æ®æœåŠ¡å·²åœæ­¢")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
